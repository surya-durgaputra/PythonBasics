{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Four main object types in beautiful soup:\n",
    "- BeautifulSoup object\n",
    "- Tag object\n",
    "- NavigableString object\n",
    "- Comment object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### BeautifulSoup object\n",
    "Lets set an HTML document that we want to use as a markup.We'll call that document html_doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create an html object that contains all the HTML \n",
    "html_doc = '''\n",
    "<html><head><title>Best Books</title></head>\n",
    "<body>\n",
    "<p class='title'><b>DATA SCIENCE FOR DUMMIES</b></p>\n",
    "\n",
    "<p class='description'>Jobs in data science abound, but few people have the data science skills needed to fill these increasingly important roles in organizations. Data Science For Dummies is the pe\n",
    "<br><br>\n",
    "Edition 1 of this book:\n",
    "        <br>\n",
    " <ul>\n",
    "  <li>Provides a background in data science fundamentals before moving on to working with relational databases and unstructured data and preparing your data for analysis</li>\n",
    "  <li>Details different data visualization techniques that can be used to showcase and summarize your data</li>\n",
    "  <li>Explains both supervised and unsupervised machine learning, including regression, model validation, and clustering techniques</li>\n",
    "  <li>Includes coverage of big data processing tools like MapReduce, Hadoop, Storm, and Spark</li>   \n",
    "  </ul>\n",
    "<br><br>\n",
    "What to do next:\n",
    "<br>\n",
    "<a href='http://www.data-mania.com/blog/books-by-lillian-pierson/' class = 'preview' id='link 1'>See a preview of the book</a>,\n",
    "<a href='http://www.data-mania.com/blog/data-science-for-dummies-answers-what-is-data-science/' class = 'preview' id='link 2'>get the free pdf download,</a> and then\n",
    "<a href='http://bit.ly/Data-Science-For-Dummies' class = 'preview' id='link 3'>buy the book!</a> \n",
    "</p>\n",
    "\n",
    "<p class='description'>...</p>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "<html><head><title>Best Books</title></head>\n",
      "<body>\n",
      "<p class=\"title\"><b>DATA SCIENCE FOR DUMMIES</b></p>\n",
      "<p class=\"description\">Jobs in data science abound, but few people have the data science skills needed to fill these increasingly important roles in organizations. Data Science For Dummies is the pe\n",
      "<br/><br/>\n",
      "Edition 1 of this book:\n",
      "        <br/>\n",
      "<ul>\n",
      "<li>Provides a background in data science fundamentals before moving on to working with relational databases and unstructured data and preparing your data for analysis</li>\n",
      "<li>Details different data visualization techniques that can be used to showcase and summarize your data</li>\n",
      "<li>Explains both supervised and unsupervised machine learning, including regression, model validation, and clustering techniques</li>\n",
      "<li>Includes coverage of big data processing tools like MapReduce, Hadoop, Storm, and Spark</li>\n",
      "</ul>\n",
      "<br/><br/>\n",
      "What to do next:\n",
      "<br/>\n",
      "<a class=\"preview\" href=\"http://www.data-mania.com/blog/books-by-lillian-pierson/\" id=\"link 1\">See a preview of the book</a>,\n",
      "<a class=\"preview\" href=\"http://www.data-mania.com/blog/data-science-for-dummies-answers-what-is-data-science/\" id=\"link 2\">get the free pdf download,</a> and then\n",
      "<a class=\"preview\" href=\"http://bit.ly/Data-Science-For-Dummies\" id=\"link 3\">buy the book!</a>\n",
      "</p>\n",
      "<p class=\"description\">...</p>\n",
      "</body></html>\n"
     ]
    }
   ],
   "source": [
    "# Let's start by looking at the BeautifulSoup constructor.\n",
    "# By default the constructor will attempt to detect what parser type you need,\n",
    "# based on the document object you pass in.\n",
    "# Let's pick a parser for our constructor instead.\n",
    "# Create a beautiful soup object that contains the html inside the html object we created\n",
    "soup = BeautifulSoup(html_doc,'html.parser')\n",
    "# here html.parser explicitly tells the constructor that we want to use the html parser\n",
    "# soup is going to be a BeautifulSoup object and is going to be a parsed HTML tree\n",
    "# What BeautifulSoup does is it transforms the markup in html_doc into a parse tree,\n",
    "# the markup into a parse tree representing the structure of the document.\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   Best Books\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <p class=\"title\">\n",
      "   <b>\n",
      "    DATA SCIENCE FOR DUMMIES\n",
      "   </b>\n",
      "  </p>\n",
      "  <p class=\"description\">\n",
      "   Jobs in data science abound, but few people have the data science skills needed to fill these increasingly important roles in organizations. Data Science For Dummies is the pe\n",
      "   <br/\n"
     ]
    }
   ],
   "source": [
    "# we see that this is bit difficult to read since there is no structure in the printed \n",
    "# output. Let's prettify it and print the first 350 elements\n",
    "print(soup.prettify()[:350])\n",
    "# And you see it added some structure, which makes it a little easier to read."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tag Object\n",
    "- A tag object represents HTML or XML elements that are present in the original markup document.\n",
    "- <a href=\"www.google.com\">\n",
    "    - Above is a tag object\n",
    "    - a is the tag name\n",
    "    - href is the tag attribute\n",
    "- Tag objects have two very important features:\n",
    "    - names\n",
    "    - attributes\n",
    "        - You can use attributes to reference, search, and navigate data by tagging BeautifulSoup.\n",
    "\n",
    "We'll first look at name attribute. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AccDEV3\\Anaconda3\\lib\\site-packages\\bs4\\__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 193 of the file C:\\Users\\AccDEV3\\Anaconda3\\lib\\runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP})\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup(YOUR_MARKUP, \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    }
   ],
   "source": [
    "# Let's create a BeautifulSoup object, and again, call it soup.\n",
    "# We'll call our BeautifulSoup constructor, and then we're going to pass in\n",
    "# a body element from our HTML document.\n",
    "# I'm going to type that in, so it's going to be b body, and then we'll put a description,\n",
    "# and then we want product description, and close the tag, and then we'll say html.\n",
    "# When we pass in the HTML argument, it tells the constructor that it should\n",
    "# interpret the tag as HTML markup.\n",
    "# For explanation, we will look at b tag. This is a bad example because this\n",
    "# is more like xml and not html. \n",
    "soup = BeautifulSoup('<b body=\"description\">Product Description</b>','html')\n",
    "# Ignore the warning for this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Tag"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Next, we will create a tag variable, and set it equal to the soup.b\n",
    "tag = soup.b\n",
    "# This essentially tells BeautifulSoup that the tag's name is b, a reference to the HTML we passed in.\n",
    "type(tag)\n",
    "# we can see that we get back a bs4.element.Tag identifier for our tag object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<b body=\"description\">Product Description</b>\n"
     ]
    }
   ],
   "source": [
    "# Let's print this tag, we'll say print tag, and this is our tag, it's the HTML\n",
    "# we passed into the BeautifulSoup constructor.\n",
    "print(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag.name\n",
    "# So, when we say tag.name, it returns a string that reads b.\n",
    "# because this is the name of the tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bestbooks body=\"description\">Product Description</bestbooks>\n",
      "bestbooks\n"
     ]
    }
   ],
   "source": [
    "# And, if you want to replace the name b with best books instead, you could just say tag.name,\n",
    "# and set the name as best books.\n",
    "tag.name = 'bestbooks'\n",
    "print(tag)\n",
    "# again note that the example looks more like xml element and not HTML element\n",
    "print(tag.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Now, let's look at working with attributes.\n",
    "A tag can have any variety of attributes, you can access a tag's attributes by treating the tag like a dictionary. For example, if we write tag and select body and run this, it returns a string that reads description. That is directly from the markup we passed into the BeautifulSoup constructor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'description'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag['body']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To return a dictionary that contains all of the tag's attributes, you can access that directly using the attrs method. We'll write the name of our tag, and then call attrs off of it. And as you can see here, we have one tag called body, and it's value is description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'body': 'description'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can easily add an attribute to a tag by simply attaching a attribute label to the tag object, and setting it equal to some value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'body': 'description', 'id': 3}\n",
      "<bestbooks body=\"description\" id=\"3\">Product Description</bestbooks>\n"
     ]
    }
   ],
   "source": [
    "tag['id'] = 3\n",
    "print(tag.attrs)\n",
    "print(tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To delete an attribute from the tag, just say del and write the attribute name you want to delete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bestbooks>Product Description</bestbooks>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del tag['body']\n",
    "del tag['id']\n",
    "tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can call the attrs method now and all we'll get back is an empty dictionary, meaning that we successfully deleted all of our attributes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag.attrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### use tags to navigate a parse tree\n",
    "Now, let's look at how to use tags to navigate a parse tree.\n",
    "\n",
    "To navigate to a specific portion of the tree, simply write the name of the tag you're interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we'll recreate the parse tree we created earlier\n",
    "soup = BeautifulSoup(html_doc,'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Best Books</title>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, to retrieve certain tags from within the parse tree, \n",
    "# all you have to do is write the name of the tag.\n",
    "soup.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to pull up the name of the book, well let's look and see what part of the tree it's located in. Primarily, it's located in the body tag, but more specifically, it's located within the b tag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<b>DATA SCIENCE FOR DUMMIES</b>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.body.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to retrieve the first tag on the HTML document that contains a web link:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<a class=\"preview\" href=\"http://www.data-mania.com/blog/books-by-lillian-pierson/\" id=\"link 1\">See a preview of the book</a>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NavigableString object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.Tag"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#NavigableString objects are the strings contained within a tag object.\n",
    "#For example: \"<b>Hello World</b>\"\n",
    "#Here, \"Hello World\" will constitute the navigable string object inside the b tag object.\n",
    "tag = soup.b\n",
    "type(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'b'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<b>DATA SCIENCE FOR DUMMIES</b>\n"
     ]
    }
   ],
   "source": [
    "print(tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DATA SCIENCE FOR DUMMIES'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to get any string contained within this tag,\n",
    "tag.string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.element.NavigableString"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(tag.string)\n",
    "# you ca see that this string is of type NavigableString"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DATA SCIENCE FOR DUMMIES'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nav_string = tag.string\n",
    "nav_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<b>Replaced Book Title</b>\n"
     ]
    }
   ],
   "source": [
    "#if you want to replace this string object with someother string, you can call the ReplaceWith method\n",
    "tag.string.replaceWith('Replaced Book Title')\n",
    "print(tag)\n",
    "# please note that this will replace the string in-place in the html tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "<html><head><title>Best Books</title></head>\n",
       "<body>\n",
       "<p class=\"title\"><b>DATA SCIENCE FOR DUMMIES</b></p>\n",
       "<p class=\"description\">Jobs in data science abound, but few people have the data science skills needed to fill these increasingly important roles in organizations. Data Science For Dummies is the pe\n",
       "<br/><br/>\n",
       "Edition 1 of this book:\n",
       "        <br/>\n",
       "<ul>\n",
       "<li>Provides a background in data science fundamentals before moving on to working with relational databases and unstructured data and preparing your data for analysis</li>\n",
       "<li>Details different data visualization techniques that can be used to showcase and summarize your data</li>\n",
       "<li>Explains both supervised and unsupervised machine learning, including regression, model validation, and clustering techniques</li>\n",
       "<li>Includes coverage of big data processing tools like MapReduce, Hadoop, Storm, and Spark</li>\n",
       "</ul>\n",
       "<br/><br/>\n",
       "What to do next:\n",
       "<br/>\n",
       "<a class=\"preview\" href=\"http://www.data-mania.com/blog/books-by-lillian-pierson/\" id=\"link 1\">See a preview of the book</a>,\n",
       "<a class=\"preview\" href=\"http://www.data-mania.com/blog/data-science-for-dummies-answers-what-is-data-science/\" id=\"link 2\">get the free pdf download,</a> and then\n",
       "<a class=\"preview\" href=\"http://bit.ly/Data-Science-For-Dummies\" id=\"link 3\">buy the book!</a>\n",
       "</p>\n",
       "<p class=\"description\">...</p>\n",
       "</body></html>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup = BeautifulSoup(html_doc,\"html.parser\")\n",
    "soup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Best Books'\n",
      "'DATA SCIENCE FOR DUMMIES'\n",
      "'Jobs in data science abound, but few people have the data science skills needed to fill these increasingly important roles in organizations. Data Science For Dummies is the pe'\n",
      "'Edition 1 of this book:'\n",
      "'Provides a background in data science fundamentals before moving on to working with relational databases and unstructured data and preparing your data for analysis'\n",
      "'Details different data visualization techniques that can be used to showcase and summarize your data'\n",
      "'Explains both supervised and unsupervised machine learning, including regression, model validation, and clustering techniques'\n",
      "'Includes coverage of big data processing tools like MapReduce, Hadoop, Storm, and Spark'\n",
      "'What to do next:'\n",
      "'See a preview of the book'\n",
      "','\n",
      "'get the free pdf download,'\n",
      "'and then'\n",
      "'buy the book!'\n",
      "'...'\n"
     ]
    }
   ],
   "source": [
    "# you can get all the NavigableStrings contained within a parsed tree using a stripped_strings generator\n",
    "for string in soup.stripped_strings:\n",
    "    print(repr(string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stripped_strings will ignore strings consisting entirely of white spaces\n",
    "#stripped_strings will remove white space at the beginning and the end of the strings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### how to access parent tag objects within a parse tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Best Books</title>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's create a new object called title tag.\n",
    "title_tag = soup.title\n",
    "title_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<head><title>Best Books</title></head>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now, if we wanted to access the parent of the title tag,\n",
    "#all we have to do is say title_tag.parent\n",
    "#and that will return the title element's parent.\n",
    "title_tag.parent\n",
    "#In this case the parent of title tag is head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'head'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_tag.parent.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### so remember, we use NavigableString objects to retrieve chunks of strings within the tag objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = '''\n",
    "<html><head><title>Best Books</title></head>\n",
    "<body>\n",
    "<p class='title'><b>DATA SCIENCE FOR DUMMIES</b></p>\n",
    "\n",
    "<p class='description'>Jobs in data science abound, but few people have the data science skills needed to fill these increasingly important roles in organizations. Data Science For Dummies is the pe\n",
    "<br><br>\n",
    "Edition 1 of this book:\n",
    "        <br>\n",
    " <ul>\n",
    "  <li>Provides a background in data science fundamentals before moving on to working with relational databases and unstructured data and preparing your data for analysis</li>\n",
    "  <li>Details different data visualization techniques that can be used to showcase and summarize your data</li>\n",
    "  <li>Explains both supervised and unsupervised machine learning, including regression, model validation, and clustering techniques</li>\n",
    "  <li>Includes coverage of big data processing tools like MapReduce, Hadoop, Storm, and Spark</li>   \n",
    "  </ul>\n",
    "<br><br>\n",
    "What to do next:\n",
    "<br>\n",
    "<a href='http://www.data-mania.com/blog/books-by-lillian-pierson/' class = 'preview' id='link 1'>See a preview of the book</a>,\n",
    "<a href='http://www.data-mania.com/blog/data-science-for-dummies-answers-what-is-data-science/' class = 'preview' id='link 2'>get the free pdf download,</a> and then\n",
    "<a href='http://bit.ly/Data-Science-For-Dummies' class = 'preview' id='link 3'>buy the book!</a> \n",
    "</p>\n",
    "\n",
    "<p class='description'>...</p>\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this time, lets use lxml parser\n",
    "soup = BeautifulSoup(r, 'lxml')\n",
    "type(soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   Best Books\n",
      "  </title>\n",
      " </head>\n",
      " <body>\n",
      "  <p class=\"title\">\n",
      "   <b>\n",
      "    DA\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify()[0:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting data from a parse tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Books\n",
      "\n",
      "DATA SCIENCE FOR DUMMIES\n",
      "Jobs in data science abound, but few people have the data science skills needed to fill these increasingly important roles in organizations. Data Science For Dummies is the pe\n",
      "\n",
      "Edition 1 of this book:\n",
      "        \n",
      "\n",
      "Provides a background in data science fundamentals before moving on to working with relational databases and unstructured data and preparing your data for analysis\n",
      "Details different data visualization techniques that can be used to showcase and summarize your data\n",
      "Explains both supervised and unsupervised machine learning, including regression, model validation, and clustering techniques\n",
      "Includes coverage of big data processing tools like MapReduce, Hadoop, Storm, and Spark\n",
      "\n",
      "\n",
      "What to do next:\n",
      "\n",
      "See a preview of the book,\n",
      "get the free pdf download, and then\n",
      "buy the book!\n",
      "...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_only = soup.get_text()\n",
    "print(text_only)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searching and retrieving data from a parse tree\n",
    "\n",
    "#### Retrieving tags by filtering with name arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<li>Provides a background in data science fundamentals before moving on to working with relational databases and unstructured data and preparing your data for analysis</li>,\n",
       " <li>Details different data visualization techniques that can be used to showcase and summarize your data</li>,\n",
       " <li>Explains both supervised and unsupervised machine learning, including regression, model validation, and clustering techniques</li>,\n",
       " <li>Includes coverage of big data processing tools like MapReduce, Hadoop, Storm, and Spark</li>]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To return all the tags that contain HTML list items\n",
    "# call the find_all method off a soup object\n",
    "# and then pass in the name of the tag, li.\n",
    "soup.find_all(\"li\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving tags by filtering with keyword arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<a class=\"preview\" href=\"http://bit.ly/Data-Science-For-Dummies\" id=\"link 3\">buy the book!</a>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#To return all of the tags that contain an id attribute of three:\n",
    "# the find_all method internally uses match method to filter only those tags with id=3 \n",
    "soup.find_all(id=\"link 3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving tags by filtering with string arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<ul>\n",
       " <li>Provides a background in data science fundamentals before moving on to working with relational databases and unstructured data and preparing your data for analysis</li>\n",
       " <li>Details different data visualization techniques that can be used to showcase and summarize your data</li>\n",
       " <li>Explains both supervised and unsupervised machine learning, including regression, model validation, and clustering techniques</li>\n",
       " <li>Includes coverage of big data processing tools like MapReduce, Hadoop, Storm, and Spark</li>\n",
       " </ul>]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# In this method you search for tags by filtering based on an exact string.\n",
    "# We do that by writing the name of our soup object\n",
    "# and then calling the find_all method off of it\n",
    "soup.find_all('ul')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving tags by filtering with list of objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<b>DATA SCIENCE FOR DUMMIES</b>, <ul>\n",
       " <li>Provides a background in data science fundamentals before moving on to working with relational databases and unstructured data and preparing your data for analysis</li>\n",
       " <li>Details different data visualization techniques that can be used to showcase and summarize your data</li>\n",
       " <li>Explains both supervised and unsupervised machine learning, including regression, model validation, and clustering techniques</li>\n",
       " <li>Includes coverage of big data processing tools like MapReduce, Hadoop, Storm, and Spark</li>\n",
       " </ul>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(['ul', 'b'])\n",
    "#this will return all the tags that have tagname ul or b\n",
    "#the reason b got listed first was because it was higher up in the HTML tree hierarchy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving tags by filtering with regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "html\n",
      "title\n",
      "ul\n",
      "li\n",
      "li\n",
      "li\n",
      "li\n"
     ]
    }
   ],
   "source": [
    "# to return all of the tags that contain a regular expression, you can use a\n",
    "# regular expression object to be used as a filter\n",
    "# this will list all tags that contain the letter l in their tag name\n",
    "import re\n",
    "l = re.compile('l')\n",
    "for tag in soup.find_all(l): print(tag.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving tags by filtering with a Boolean value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "html\n",
      "head\n",
      "title\n",
      "body\n",
      "p\n",
      "b\n",
      "p\n",
      "br\n",
      "br\n",
      "br\n",
      "ul\n",
      "li\n",
      "li\n",
      "li\n",
      "li\n",
      "br\n",
      "br\n",
      "br\n",
      "a\n",
      "a\n",
      "a\n",
      "p\n"
     ]
    }
   ],
   "source": [
    "#In this method you search for tags by filtering based on true, false values.\n",
    "#To return all of the tags that are contained in a parse tree\n",
    "#you can pass in a Boolean value to use as a filter.\n",
    "#The find_all function accepts Boolean values.\n",
    "#So if you want to print out all HTML tags from within the soup object,\n",
    "#we can just use that same loop but pass in the value true\n",
    "#as an argument to the find_all function.\n",
    "for tag in soup.find_all(True): print(tag.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving weblinks by filtering with string objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://www.data-mania.com/blog/books-by-lillian-pierson/\n",
      "http://www.data-mania.com/blog/data-science-for-dummies-answers-what-is-data-science/\n",
      "http://bit.ly/Data-Science-For-Dummies\n"
     ]
    }
   ],
   "source": [
    "#to return all the web-links within a parse tree, you can use a string object inside find_all \n",
    "# to use as a filter. Lets start by isolating all the web-links within the soup object.\n",
    "# We do that by calling the find_all method off of the soup object, and passing in the tag a.\n",
    "#We will write a for loop that passes through every tag in the soup object to search for all the a tags.\n",
    "# For each a tag that it finds, it gets the href value and prints that out.\n",
    "for link in soup.find_all('a'): print(link.get('href'))\n",
    "    # That is a simple mechanism you can use to scrape web links from a web page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieving strings by filtering with regular expressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Jobs in data science abound, but few people have the data science skills needed to fill these increasingly important roles in organizations. Data Science For Dummies is the pe\\n',\n",
       " 'Provides a background in data science fundamentals before moving on to working with relational databases and unstructured data and preparing your data for analysis',\n",
       " 'Details different data visualization techniques that can be used to showcase and summarize your data',\n",
       " 'Includes coverage of big data processing tools like MapReduce, Hadoop, Storm, and Spark']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To return all of the strings that contain a regular expression,\n",
    "# you can pass in a regular expression object to use as a filter.\n",
    "soup.find_all(string=re.compile(\"data\"))\n",
    "# The find_all method then returns a list of strings from the original web page,\n",
    "#all of which contain the word data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web scraping in action\n",
    "In the following demonstration, I'm going to show you how to scrape webpage and then save your results\n",
    "in an external file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import urllib #we're going to need urllib library in order to read in our data from the internet.\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bs4.BeautifulSoup"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Scraping a webpage and saving your results\n",
    "r = urllib.request.urlopen('https://analytics.usa.gov').read()\n",
    "soup = BeautifulSoup(r,'lxml')\n",
    "type(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<!DOCTYPE html>\\n<html lang=\"en\">\\n <!-- Initalize title and data source variables -->\\n <head>\\n  <!--\\n'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.prettify()[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/\n",
      "#explanation\n",
      "https://analytics.usa.gov/data/\n",
      "data/\n",
      "#top-pages-realtime\n",
      "#top-pages-7-days\n",
      "#top-pages-30-days\n",
      "https://analytics.usa.gov/data/live/all-pages-realtime.csv\n",
      "https://analytics.usa.gov/data/live/all-domains-30-days.csv\n",
      "https://www.digitalgov.gov/services/dap/\n",
      "https://www.digitalgov.gov/services/dap/common-questions-about-dap-faq/#part-4\n",
      "https://support.google.com/analytics/answer/2763052?hl=en\n",
      "https://analytics.usa.gov/data/live/second-level-domains.csv\n",
      "https://analytics.usa.gov/data/live/sites.csv\n",
      "mailto:DAP@support.digitalgov.gov\n",
      "https://analytics.usa.gov/data/\n",
      "https://analytics.usa.gov/developer\n",
      "mailto:DAP@support.digitalgov.gov\n",
      "https://github.com/GSA/analytics.usa.gov/issues\n",
      "https://github.com/GSA/analytics.usa.gov\n",
      "https://github.com/18F/analytics-reporter\n",
      "http://www.gsa.gov/\n",
      "https://www.digitalgov.gov/services/dap/\n",
      "https://cloud.gov/\n"
     ]
    }
   ],
   "source": [
    "#now lets print all the links on this page\n",
    "for link in soup.find_all('a'):\n",
    "    print(link.get('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"https://analytics.usa.gov/data/\">Data</a>\n",
      "<a href=\"https://analytics.usa.gov/data/live/all-pages-realtime.csv\">Download the full dataset.</a>\n",
      "<a href=\"https://analytics.usa.gov/data/live/all-domains-30-days.csv\">Download the full dataset.</a>\n",
      "<a class=\"external-link\" href=\"https://www.digitalgov.gov/services/dap/\">Digital Analytics Program</a>\n",
      "<a class=\"external-link\" href=\"https://www.digitalgov.gov/services/dap/common-questions-about-dap-faq/#part-4\">does not track individuals</a>\n",
      "<a class=\"external-link\" href=\"https://support.google.com/analytics/answer/2763052?hl=en\">anonymizes the IP addresses</a>\n",
      "<a class=\"external-link\" href=\"https://analytics.usa.gov/data/live/second-level-domains.csv\">400 executive branch government domains</a>\n",
      "<a class=\"external-link\" href=\"https://analytics.usa.gov/data/live/sites.csv\">about 5,700 total websites</a>\n",
      "<a href=\"https://analytics.usa.gov/data/\">download the data here.</a>\n",
      "<a href=\"https://analytics.usa.gov/developer\"> API project</a>\n",
      "<a class=\"usa-button usa-button-secondary-inverse\" href=\"https://github.com/GSA/analytics.usa.gov/issues\">\n",
      "<img alt=\"Github Icon\" class=\"github-icon\" src=\"/images/github-logo-white.svg\"/>\n",
      "                  Suggest a feature or report an issue\n",
      "            </a>\n",
      "<a href=\"https://github.com/GSA/analytics.usa.gov\">\n",
      "<img alt=\"Github Icon\" class=\"github-icon\" src=\"/images/github-logo.svg\"/>\n",
      "              View our code on GitHub</a>\n",
      "<a href=\"https://github.com/18F/analytics-reporter\">\n",
      "<img alt=\"Github Icon\" class=\"github-icon\" src=\"/images/github-logo.svg\"/>\n",
      "              View our code for the data on GitHub</a>\n",
      "<a href=\"http://www.gsa.gov/\">\n",
      "<img alt=\"GSA\" src=\"/images/gsa-logo.svg\"/>\n",
      "</a>\n",
      "<a href=\"https://www.digitalgov.gov/services/dap/\">Digital Analytics Program</a>\n",
      "<a href=\"https://cloud.gov/\">cloud.gov</a>\n"
     ]
    }
   ],
   "source": [
    "#lets find all the a tags that have an attribute of href\n",
    "#and then of all of these tags that are returned, we want the loop\n",
    "#to match against them a regular expression that reads http, and print out only those.\n",
    "for link in soup.find_all('a',attrs={'href':re.compile('^http')}):\n",
    "    print(link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It isnt useful to have your results stuck in a Jupyter notebook. So we will now\n",
    "save this to an external file.\n",
    "To do that, we're going to create a new text file called parsed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a href=\"https://analytics.usa.gov/data/\">Data</a>\n",
      "<a href=\"https://analytics.usa.gov/data/live/all-pages-realtime.csv\">Download the full dataset.</a>\n",
      "<a href=\"https://analytics.usa.gov/data/live/all-domains-30-days.csv\">Download the full dataset.</a>\n",
      "<a class=\"external-link\" href=\"https://www.digitalgov.gov/services/dap/\">Digital Analytics Program</a>\n",
      "<a class=\"external-link\" href=\"https://www.digitalgov.gov/services/dap/common-questions-about-dap-faq/#part-4\">does not track individuals</a>\n",
      "<a class=\"external-link\" href=\"https://support.google.com/analytics/answer/2763052?hl=en\">anonymizes the IP addresses</a>\n",
      "<a class=\"external-link\" href=\"https://analytics.usa.gov/data/live/second-level-domains.csv\">400 executive branch government domains</a>\n",
      "<a class=\"external-link\" href=\"https://analytics.usa.gov/data/live/sites.csv\">about 5,700 total websites</a>\n",
      "<a href=\"https://analytics.usa.gov/data/\">download the data here.</a>\n",
      "<a href=\"https://analytics.usa.gov/developer\"> API project</a>\n",
      "<a class=\"usa-button usa-button-secondary-inverse\" href=\"https://github.com/GSA/analytics.usa.gov/issues\">\n",
      "<img alt=\"Github Icon\" class=\"github-icon\" src=\"/images/github-logo-white.svg\"/>\n",
      "                  Suggest a feature or report an issue\n",
      "            </a>\n",
      "<a href=\"https://github.com/GSA/analytics.usa.gov\">\n",
      "<img alt=\"Github Icon\" class=\"github-icon\" src=\"/images/github-logo.svg\"/>\n",
      "              View our code on GitHub</a>\n",
      "<a href=\"https://github.com/18F/analytics-reporter\">\n",
      "<img alt=\"Github Icon\" class=\"github-icon\" src=\"/images/github-logo.svg\"/>\n",
      "              View our code for the data on GitHub</a>\n",
      "<a href=\"http://www.gsa.gov/\">\n",
      "<img alt=\"GSA\" src=\"/images/gsa-logo.svg\"/>\n",
      "</a>\n",
      "<a href=\"https://www.digitalgov.gov/services/dap/\">Digital Analytics Program</a>\n",
      "<a href=\"https://cloud.gov/\">cloud.gov</a>\n"
     ]
    }
   ],
   "source": [
    "file = open('parsed_data.txt','w')#'w' to tell Python we want to write into this text file.\n",
    "for link in soup.find_all('a',attrs={'href':re.compile('^http')}):\n",
    "    soup_link = str(link)\n",
    "    print(soup_link)\n",
    "    file.write(soup_link)\n",
    "file.flush()\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\AccDEV3\\\\Desktop\\\\VS\\\\Pt\\\\PythonBasics\\\\DataScienceET\\\\WebScrapingWithBeautifulSoup'"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to find out where this created data file is,\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#note that in the created file, you will have the stray tags like <a href=\"  etc.\n",
    "#so you will need to do some data munging to clean up the urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "url = 'http://www.imdb.com/search/title'\n",
    "data = {\n",
    "    'sort':'num_votes,desc'\n",
    "}\n",
    "data['release_date'] = 2017\n",
    "data['page'] = 1\n",
    "response = requests.get(url,data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html xmlns:fb=\"http://www.facebook.com/2008/fbml\" xmlns:og=\"http://ogp.me/ns#\">\n",
      " <head>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <meta content=\"IE=edge\" http-equiv=\"X-UA-Compatible\"/>\n",
      "  <meta content=\"app-id=342792525, app-argument=imdb:///?src=mdot\" name=\"apple-itunes-app\"/>\n",
      "  <script type=\"text/javascript\">\n",
      "   var IMDbTimer={starttime: new Date().getTime(),pt:'java'};\n",
      "  </script>\n",
      "  <script>\n",
      "   if (typeof uet == 'function') {\n",
      "      uet(\"bb\", \"LoadTitle\", {wb: 1});\n",
      "    }\n",
      "  </script>\n",
      "  <script>\n",
      "   (function(t){ (t.events = t.events || {})[\"csm_head_pre_title\"] = new Date().getTime(); })(IMDbTimer);\n",
      "  </script>\n",
      "  <title>\n",
      "   IMDb: Released between 2017-01-01 and 2017-12-31\n",
      "(Sorted by Number of Votes Descending) - IMDb\n",
      "  </title>\n",
      "  <script>\n",
      "   (function(t){ (t.events = t.events || {})[\"csm_head_post_title\"] = new Date().getTime(); })(IMDbTimer);\n",
      "  </script>\n",
      "  <script>\n",
      "   if (typeof uet == 'function') {\n",
      "      uet(\"be\", \"LoadTitle\", {wb: 1});\n",
      "    }\n",
      "  </script>\n",
      "  <script>\n",
      "   if (typeof ue\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup = BeautifulSoup(response.text,'html.parser')\n",
    "print(soup.prettify()[:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
