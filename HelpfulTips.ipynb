{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- if you want to see docstring for any method, there are two ways\n",
    "    - pd.read_csv then when curser is after v, hit shift+tab. It will open the docstring. shift+tab again will show more docstring. If you hit shift+tab 3 times, it will show entire docstring in a separate dock\n",
    "    - put a ? after a method name (and shift+Enter) to read the docstring (this will open the entire docstring in a separate dock). Like pd.read_csv? then shift+Enter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sepal accuracy\n",
      "______________\n",
      "0.6578947368421053\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       1.00      0.88      0.93         8\n",
      " versicolor       0.44      0.36      0.40        11\n",
      "  virginica       0.64      0.74      0.68        19\n",
      "\n",
      "avg / total       0.66      0.66      0.65        38\n",
      "\n",
      "[[ 7  0  1]\n",
      " [ 0  4  7]\n",
      " [ 0  5 14]]\n",
      "Petal accuracy\n",
      "______________\n",
      "0.9473684210526315\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "     setosa       1.00      1.00      1.00         8\n",
      " versicolor       0.91      0.91      0.91        11\n",
      "  virginica       0.95      0.95      0.95        19\n",
      "\n",
      "avg / total       0.95      0.95      0.95        38\n",
      "\n",
      "[[ 8  0  0]\n",
      " [ 0 10  1]\n",
      " [ 0  1 18]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AccDEV3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "def sklearn_dataset_to_df(dataset):\n",
    "    df = pd.DataFrame(dataset.data, columns=dataset.feature_names)\n",
    "    df['target'] = dataset.target\n",
    "    return df\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "df = sklearn_dataset_to_df(iris)\n",
    "X_iris = df.drop(columns=['target'])\n",
    "y_iris = df['target']\n",
    "X_s, y_s = X_iris.loc[:,:'sepal width (cm)'],y_iris\n",
    "X_p, y_p = X_iris.loc[:,'petal length (cm)':'petal width (cm)'], y_iris\n",
    "X_s_train, X_s_test, y_s_train, y_s_test = train_test_split(X_s,y_s,test_size=0.25,random_state=33)\n",
    "X_p_train, X_p_test, y_p_train, y_p_test = train_test_split(X_p,y_p,test_size=0.25,random_state=33)\n",
    "#always scale before running predictives\n",
    "scaler_s = StandardScaler().fit(X_s_train)\n",
    "scaler_p = StandardScaler().fit(X_p_train)\n",
    "X_s_train_scaled = scaler_s.transform(X_s_train)\n",
    "X_p_train_scaled = scaler_p.transform(X_p_train)\n",
    "X_s_test_scaled = scaler_s.transform(X_s_test)\n",
    "X_p_test_scaled = scaler_p.transform(X_p_test)\n",
    "\n",
    "clf_p = SGDClassifier()\n",
    "clf_s = SGDClassifier()\n",
    "\n",
    "clf_s.fit(X_s_train_scaled, y_s_train)\n",
    "clf_p.fit(X_p_train_scaled, y_p_train)\n",
    "\n",
    "# always run predictions on test to check \n",
    "y_s_pred = clf_s.predict(X_s_test_scaled)\n",
    "y_p_pred = clf_p.predict(X_p_test_scaled)\n",
    "\n",
    "#get metrics\n",
    "print(\"Sepal accuracy\")\n",
    "print(\"______________\")\n",
    "print(metrics.accuracy_score(y_s_test,y_s_pred))\n",
    "print(metrics.classification_report(y_s_test, y_s_pred, target_names=iris.target_names))\n",
    "print(metrics.confusion_matrix(y_s_test,y_s_pred))\n",
    "print(\"Petal accuracy\")\n",
    "print(\"______________\")\n",
    "print(metrics.accuracy_score(y_p_test,y_p_pred))\n",
    "print(metrics.classification_report(y_p_test, y_p_pred, target_names=iris.target_names))\n",
    "print(metrics.confusion_matrix(y_p_test,y_p_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AccDEV3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\AccDEV3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\AccDEV3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\AccDEV3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\AccDEV3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\AccDEV3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\AccDEV3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\AccDEV3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\AccDEV3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n",
      "C:\\Users\\AccDEV3\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.stochastic_gradient.SGDClassifier'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# use cross validation to improve score\n",
    "from sklearn.cross_validation import cross_val_score, KFold\n",
    "from sklearn.pipeline import Pipeline\n",
    "clf = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('linear_model', SGDClassifier())\n",
    "])\n",
    "# create a k-fold cross validation iterator of k=5 folds\n",
    "cv = KFold(X_s_train.shape[0], 5, shuffle=True, random_state=33)\n",
    "scores_s = cross_val_score(clf, X_s_train, y_s_train, cv=cv)\n",
    "scores_p = cross_val_score(clf, X_p_train, y_p_train, cv=cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.86956522 0.69565217 0.72727273 0.81818182 0.90909091]\n",
      "[0.73913043 0.95652174 0.77272727 0.59090909 0.90909091]\n"
     ]
    }
   ],
   "source": [
    "print(scores_s)\n",
    "print(scores_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
